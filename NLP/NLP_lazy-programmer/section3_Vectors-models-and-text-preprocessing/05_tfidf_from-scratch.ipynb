{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk,string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/snehil/work/DataVault/02_lazy_programmer_nlp/tmdb_5000_movies.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tagline','title']]\n",
    "df.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc'] = df.tagline+' '+df.title\n",
    "df.doc = df.doc.apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>enter the world of pandora. avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>at the end of the world, the adventure begins....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>a plan no one escapes spectre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>the legend ends the dark knight rises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>lost in our world, found in another. john carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>He didn't come looking for trouble, but troubl...</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>he didn't come looking for trouble, but troubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>a newlywed couple's honeymoon is upended by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td></td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>signed, sealed, delivered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>A New Yorker in Shanghai</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>a new yorker in shanghai shanghai calling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td></td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>my date with drew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4803 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tagline  \\\n",
       "0                           Enter the World of Pandora.   \n",
       "1        At the end of the world, the adventure begins.   \n",
       "2                                 A Plan No One Escapes   \n",
       "3                                       The Legend Ends   \n",
       "4                  Lost in our world, found in another.   \n",
       "...                                                 ...   \n",
       "4798  He didn't come looking for trouble, but troubl...   \n",
       "4799  A newlywed couple's honeymoon is upended by th...   \n",
       "4800                                                      \n",
       "4801                           A New Yorker in Shanghai   \n",
       "4802                                                      \n",
       "\n",
       "                                         title  \\\n",
       "0                                       Avatar   \n",
       "1     Pirates of the Caribbean: At World's End   \n",
       "2                                      Spectre   \n",
       "3                        The Dark Knight Rises   \n",
       "4                                  John Carter   \n",
       "...                                        ...   \n",
       "4798                               El Mariachi   \n",
       "4799                                 Newlyweds   \n",
       "4800                 Signed, Sealed, Delivered   \n",
       "4801                          Shanghai Calling   \n",
       "4802                         My Date with Drew   \n",
       "\n",
       "                                                    doc  \n",
       "0                    enter the world of pandora. avatar  \n",
       "1     at the end of the world, the adventure begins....  \n",
       "2                         a plan no one escapes spectre  \n",
       "3                 the legend ends the dark knight rises  \n",
       "4      lost in our world, found in another. john carter  \n",
       "...                                                 ...  \n",
       "4798  he didn't come looking for trouble, but troubl...  \n",
       "4799  a newlywed couple's honeymoon is upended by th...  \n",
       "4800                          signed, sealed, delivered  \n",
       "4801          a new yorker in shanghai shanghai calling  \n",
       "4802                                  my date with drew  \n",
       "\n",
       "[4803 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent_mod = []\n",
    "    for i in sent:\n",
    "        if i.isalnum():\n",
    "            sent_mod.append(i)\n",
    "\n",
    "    return sent_mod\n",
    "\n",
    "### Removing Stopwords,Punctuation \n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(sent):\n",
    "    sent = [i for i in sent if i not in stopword and i not in string.punctuation]\n",
    "    return sent\n",
    "\n",
    "df.doc = df.doc.apply(tokenize)\n",
    "df.doc = df.doc.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else :\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def wnl_lemma(sent):\n",
    "    words_and_tags = nltk.pos_tag(sent)\n",
    "    sent_mod = []\n",
    "    for words,tags in words_and_tags:\n",
    "        tag = get_wordnet_pos(tags)\n",
    "        word = wnl.lemmatize(words, pos=tag)\n",
    "        sent_mod.append(word)\n",
    "    return sent_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.doc = df.doc.apply(wnl_lemma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Word to index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = []\n",
    "for i,row in df.iterrows():\n",
    "    for j in row['doc']:\n",
    "        if j not in unique_words:\n",
    "            unique_words.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(len(unique_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict = dict(zip(idx,unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_dict = dict(zip(unique_words,idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5809"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Count Vectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.zeros((4803,5809))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "df['count_element'] = df.doc.apply(lambda x:Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df.iterrows():\n",
    "    for key,value in row['count_element'].items():\n",
    "        idx = unique_words.index(key)\n",
    "        tf[i,idx] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total count of each word in whole corpus\n",
    "document_frequency = np.sum(tf>0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11, 177,   3, ...,   1,   1,   1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = np.log(len(df)/document_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tfidf\n",
    "tf_idf = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2385/3187243691.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  tf_idf_normalized = tf_idf/np.linalg.norm(tf_idf, axis=1).reshape(4803,1)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_normalized = tf_idf/np.linalg.norm(tf_idf, axis=1).reshape(4803,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46065552, 0.25012796, 0.55911118, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.42624673, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.48577495],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_normalized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seek', 'truth', 'da', 'vinci', 'code']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[201].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinci\n",
      "da\n",
      "seek\n",
      "code\n",
      "truth\n",
      "pointe\n"
     ]
    }
   ],
   "source": [
    "for j in (-tf_idf[201]).argsort()[:6]:\n",
    "    print(word_index_dict[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
